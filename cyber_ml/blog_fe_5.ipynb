{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from scapy.all import PcapReader\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from read_pcaps import pcap_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a variable that allows you to read prior saved pkl files\n",
    "READ_FROM_PKL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if READ_FROM_PKL:\n",
    "    mirai_df = pd.read_pickle(\"../data/blog_eda/mirai.pkl\")\n",
    "    benign_df = pd.read_pickle(\"../data/blog_eda/benign.pkl\")\n",
    "else:\n",
    "    pcap_reader_mirai = PcapReader(\"../data/blog_eda/mirai.pcap\")\n",
    "    pcap_reader_benign = PcapReader(\"../data/blog_eda/benign.pcapng\")\n",
    "    mirai_df = pcap_to_dataframe(pcap_reader_mirai)\n",
    "    benign_df = pcap_to_dataframe(pcap_reader_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read features saved, add new ones\n",
    "if READ_FROM_PKL:\n",
    "    mirai_features_df = pd.read_pickle(\"../data/blog_fe/mirai_features.pkl\")\n",
    "    benign_features_df = pd.read_pickle(\"../data/blog_fe/benign_features.pkl\")\n",
    "else:\n",
    "    print(\n",
    "        \"Error! Feature pkl not saved. Please run blog_fe_2.ipynb, blog_fe_3.ipynb, blog_fe_4.ipynb or download from here: https://drive.google.com/drive/folders/1dBQhbQtIk_fbbb80G5pSVV3hbWYJY7fv?usp=sharing\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with None\n",
    "mirai_df = mirai_df.dropna()\n",
    "benign_df = benign_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels, 0 for benign, 1 for malicious\n",
    "mirai_features_df[\"Label\"] = 1\n",
    "benign_features_df[\"Label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat([mirai_features_df, benign_features_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = shuffle(concatenated_df, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that all features are numeric, otherwise feature selection will not work\n",
    "shuffled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Initialize StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# columns_to_scale = [\"Numeric Source IP\", \"Numeric Destination IP\"]\n",
    "\n",
    "# # Apply Standardization to the DataFrame\n",
    "# df_standardized = pd.DataFrame(scaler.fit_transform(shuffled_df[columns_to_scale]), columns=columns_to_scale)\n",
    "\n",
    "# # Print the standardized DataFrame\n",
    "# print(df_standardized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_scale = [\"interarrival\", \"log_interarrival\"]\n",
    "\n",
    "# # Apply Standardization to the DataFrame\n",
    "# df_standardized = pd.DataFrame(\n",
    "#     scaler.fit_transform(shuffled_df[columns_to_scale]), columns=columns_to_scale\n",
    "# )\n",
    "\n",
    "# Print the standardized DataFrame\n",
    "# print(df_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_standardized = pd.concat(\n",
    "#     [df_standardized, shuffled_df.drop(columns=columns_to_scale)], axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_standardized = df_standardized.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"NaN values in shuffled_df:\", df_standardized.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = shuffled_df.drop(\"payload_embedding\", axis=1)\n",
    "shuffled_df_values = shuffled_df.values.astype(np.float64)\n",
    "\n",
    "# Find rows with infinite values\n",
    "inf_rows = np.isinf(shuffled_df_values).any(axis=1)\n",
    "\n",
    "# Remove rows with infinite values\n",
    "shuffled_df = shuffled_df[~inf_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with infinite values\n",
    "inf_rows = shuffled_df.index[np.isinf(shuffled_df).any(1)]\n",
    "\n",
    "# Remove rows with infinite values\n",
    "shuffled_df = shuffled_df.drop(inf_rows)\n",
    "\n",
    "# Display the DataFrame after removing rows with infinite values\n",
    "print(\"\\nDataFrame after removing rows with infinite values:\")\n",
    "print(shuffled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = shuffled_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data\n",
    "- Train\n",
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X should contain your feature columns, and y should contain the labels (0 or 1)\n",
    "X = shuffled_df.drop(columns=[\"Label\"], axis=1)\n",
    "y = shuffled_df[\"Label\"]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
    "\n",
    "# Ensure y_train is a NumPy array\n",
    "y_train_np = y_train.values if isinstance(y_train, pd.Series) else y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for infinity\n",
    "inf_mask = np.isinf(X_train_np)\n",
    "\n",
    "# Find indices where X_train_np contains infinity\n",
    "inf_indices = np.where(inf_mask)\n",
    "\n",
    "# Check for values too large for float64\n",
    "large_values_mask = np.abs(X_train_np) > np.finfo(np.float64).max\n",
    "\n",
    "# Find indices where X_train_np contains values too large for float64\n",
    "large_values_indices = np.where(large_values_mask)\n",
    "\n",
    "# Combine the two masks to find indices where X_train_np contains either infinity or values too large for float64\n",
    "problematic_indices = np.unique(\n",
    "    np.concatenate((inf_indices[0], large_values_indices[0]))\n",
    ")\n",
    "\n",
    "# Print the problematic values and their corresponding indices\n",
    "print(\"Problematic values:\")\n",
    "print(X_train_np[problematic_indices])\n",
    "print(\"Indices of problematic values:\")\n",
    "print(problematic_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top k features using SelectKBest and f_classif\n",
    "k_best = 5  # You can adjust this value based on your dataset and requirements\n",
    "selector = SelectKBest(f_classif, k=k_best)\n",
    "X_train_selected = selector.fit_transform(X_train_np, y_train_np)\n",
    "\n",
    "# Train a classifier using the selected features\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_selected, y_train_np)\n",
    "\n",
    "# Transform the test set using the same feature selector\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Make predictions and evaluate the performance\n",
    "y_pred = clf.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Selected {k_best} features using SelectKBest and f_classif.\")\n",
    "print(f\"Accuracy on the test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
