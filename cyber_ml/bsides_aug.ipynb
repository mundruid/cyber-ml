{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sweetviz as sv\n",
    "import ipaddress\n",
    "\n",
    "\n",
    "from scapy.all import PcapReader, IP, TCP, UDP, ICMP\n",
    "from scipy.stats import ttest_ind, kstest, norm, skew, kurtosis, zscore\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skimpy import skim\n",
    "from summarytools import dfSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcap_reader = PcapReader(\"../data/blog_show_data/mirai.pcap\")\n",
    "type(pcap_reader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "- convert data to streams\n",
    "- collect some numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the data\n",
    "# data = []\n",
    "\n",
    "# # Iterate through the packets in the pcap file\n",
    "# for packet in pcap_reader:\n",
    "#     # Get the source and destination IP addresses\n",
    "#     if packet.haslayer(IP):\n",
    "#         src_ip = packet[IP].src\n",
    "#         dst_ip = packet[IP].dst\n",
    "#         protocol = packet[IP].proto\n",
    "#     else:\n",
    "#         src_ip = None\n",
    "#         dst_ip = None\n",
    "#         protocol = None\n",
    "\n",
    "#     # Get the source and destination ports and payload\n",
    "#     if packet.haslayer(TCP):\n",
    "#         src_port = packet[TCP].sport\n",
    "#         dst_port = packet[TCP].dport\n",
    "#         payload = str(packet[TCP].payload)\n",
    "#         packet_len = len(packet[TCP])\n",
    "#     elif packet.haslayer(UDP):\n",
    "#         src_port = packet[UDP].sport\n",
    "#         dst_port = packet[UDP].dport\n",
    "#         payload = str(packet[UDP].payload)\n",
    "#         packet_len = len(packet[UDP])\n",
    "#     elif packet.haslayer(ICMP):\n",
    "#         payload = str(packet[ICMP].payload)\n",
    "#         packet_len = len(packet[ICMP])\n",
    "#         src_port = None\n",
    "#         dst_port = None\n",
    "#     else:\n",
    "#         src_port = None\n",
    "#         dst_port = None\n",
    "#         payload = str(packet.payload)\n",
    "#         packet_len = len(packet)\n",
    "\n",
    "#     # Append the data to the list\n",
    "#     data.append([packet.time, src_ip, dst_ip, src_port, dst_port, payload, packet_len, protocol])\n",
    "\n",
    "# # Convert the list to a pandas dataframe\n",
    "# mirai_df = pd.DataFrame(data, columns=['Timestamp', 'Source IP', 'Destination IP', 'Source Port', 'Destination Port', 'Payload', 'Packet Length', 'Protocol'])\n",
    "\n",
    "# mirai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirai_df.to_pickle(\"../data/bsides_aug/mirai.pkl\")\n",
    "mirai_df = pd.read_pickle(\"../data/bsides_aug/mirai.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store stream data as separate dataframes\n",
    "dfs = []\n",
    "\n",
    "# Group packets by src/dst IP and src/dst port\n",
    "grouped = mirai_df.groupby(\n",
    "    [\"Source IP\", \"Destination IP\", \"Source Port\", \"Destination Port\", \"Protocol\"]\n",
    ")\n",
    "\n",
    "# Iterate through each group to extract stream data\n",
    "for name, group in grouped:\n",
    "    # Get source/destination IP, port, and protocol\n",
    "    src_ip, dst_ip, src_port, dst_port, proto = name\n",
    "\n",
    "    # Get number of packets, total length, and duration of the stream\n",
    "    num_packets = len(group)\n",
    "    total_length = group[\"Packet Length\"].sum()\n",
    "    start_time = group[\"Timestamp\"].min()\n",
    "    end_time = group[\"Timestamp\"].max()\n",
    "    duration = float(end_time - start_time)\n",
    "\n",
    "    # Create a new dataframe with the stream data\n",
    "    stream_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Source IP\": [src_ip],\n",
    "            \"Destination IP\": [dst_ip],\n",
    "            \"Source Port\": [src_port],\n",
    "            \"Destination Port\": [dst_port],\n",
    "            \"Protocol\": [proto],\n",
    "            \"Number of Packets\": [num_packets],\n",
    "            \"Total Length\": [total_length],\n",
    "            \"Duration\": [duration],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add the new dataframe to the list\n",
    "    dfs.append(stream_df)\n",
    "\n",
    "# Concatenate all the dataframes in the list into one dataframe\n",
    "stream_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Print the new dataframe with stream data\n",
    "print(stream_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics & data\n",
    "\n",
    "- Describe columns and data types\n",
    "- Descriptive statistics\n",
    "  -  count, \n",
    "  -  mean, \n",
    "  -  standard deviation, \n",
    "  -  minimum, \n",
    "  -  25th percentile, \n",
    "  -  median (50th percentile), \n",
    "  -  75th percentile, and \n",
    "  -  maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe, summarize etc.\n",
    "stream_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics\n",
    "stream_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix for numerical values in dataframe\n",
    "stream_df.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "- Is the difference between two groups or variables statistically significant?\n",
    "- Use t-test to compare means of two groups\n",
    "  - assumes that data follows normal distribution\n",
    "- Types of variables\n",
    "  - dependent: the effect of a phenomenon. For example, how does number of HTTP requests mean that a network is compromised?\n",
    "  - independent: the cause. The number of HTTP requests affects whether a network is compromised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_testing(df, col1, col2):\n",
    "    group1 = df[col1]\n",
    "    group2 = df[col2]\n",
    "    pvalue = ttest_ind(group1, group2)[1]\n",
    "    if pvalue < 0.05:\n",
    "        return \"The difference between {} and {} is statistically significant (p < 0.05)\".format(\n",
    "            col1, col2\n",
    "        )\n",
    "    else:\n",
    "        return \"The difference between {} and {} is not statistically significant (p >= 0.05)\".format(\n",
    "            col1, col2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_testing(stream_df, \"Number of Packets\", \"Total Length\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis\n",
    "\n",
    "- Models relationship between a dependent variable and one or more independent variables\n",
    "- Linear regression\n",
    "  - fit data in line\n",
    "  - calculate coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_analysis(df, x_cols, y_col):\n",
    "    X = df[x_cols].values.reshape(-1, len(x_cols))\n",
    "    y = df[y_col].values.reshape(-1, 1)\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    r_sq = model.score(X, y)\n",
    "    coef = model.coef_\n",
    "    return {\"R-squared\": r_sq, \"Coefficients\": coef}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_analysis(stream_df, [\"Number of Packets\", \"Duration\"], \"Total Length\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolmogorov-Smirnov test\n",
    "\n",
    "- compare two sample distributions\n",
    "- useful for fitting to a distribution\n",
    "- test if two samples from a population:\n",
    "  - came from a distribution\n",
    "  - belong to the same distribution\n",
    "- Uses metric `D`\n",
    "  - max absolute difference between empirical distribution function of the samples and cumulative distribution of the reference distribution\n",
    "- Null hypothesis: \n",
    "  - samples came from the reference distribution\n",
    "  - samples came from the same distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kolmogorov_smirnov_test(df, column):\n",
    "    sample = df[column].values\n",
    "    _, pvalue = kstest(sample, norm.cdf, args=(sample.mean(), sample.std()))\n",
    "    if pvalue < 0.05:\n",
    "        return \"The distribution of {} is significantly different from a normal distribution (p < 0.05)\".format(\n",
    "            column\n",
    "        )\n",
    "    else:\n",
    "        return \"The distribution of {} is not significantly different from a normal distribution (p >= 0.05)\".format(\n",
    "            column\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolmogorov_smirnov_test(stream_df, \"Total Length\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness and Kyrtosis\n",
    "\n",
    "- information about the shape of the distribution\n",
    "- Skewness: measure the degree of asymmetry\n",
    "  - symmetric: equally balanced around its mean\n",
    "  - asymmetric: not equally balanced\n",
    "  - positive skewness: distribution longer on the right side\n",
    "  - negative skewness: longer on the left\n",
    "  - 0: completely symmetric\n",
    "- Kurtosis: peakedness of distribution\n",
    "  - high: sharp peak, long tails\n",
    "  - low: flat peak, short tails\n",
    "  - ex. normal distribution has kurtosis 3, mesokurtic\n",
    "    - `> 3` leptokurtic\n",
    "    - `< 3` platykurtic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness_kurtosis(df):\n",
    "    result = {}\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        result[col + \"_skewness\"] = skew(df[col])\n",
    "        result[col + \"_kurtosis\"] = kurtosis(df[col])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness_kurtosis(stream_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "- observation that significantly differs from others in a dataset\n",
    "- Causes\n",
    "  - measurement errors\n",
    "  - extreme rare values\n",
    "- significant impact in statistical analysis\n",
    "- measurements\n",
    "  - z-score: `(x - mean) / std_dev`\n",
    "  - IQR method: this method identifies outliers as observations that are below `Q1 - 1.5IQR` or above `Q3 + 1.5IQR`, where Q1 and Q3 are the first and third quartiles, and IQR is the interquartile range (the difference between Q3 and Q1).\n",
    "  - visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_zscore(df, column, threshold=3):\n",
    "    zscores = np.abs(zscore(df[column]))\n",
    "    return df[zscores > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = detect_outliers_zscore(stream_df, \"Total Length\", threshold=3)\n",
    "print(outliers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ip address to numeric values\n",
    "def ip_to_numeric(ip):\n",
    "    ip_obj = ipaddress.ip_interface(ip)\n",
    "    return int(ip_obj.network.network_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df[\"Source IP Numeric\"] = stream_df[\"Source IP\"].apply(ip_to_numeric)\n",
    "stream_df[\"Destination IP Numeric\"] = stream_df[\"Destination IP\"].apply(ip_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df_numeric = stream_df.drop(columns=[\"Source IP\", \"Destination IP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df[\"Duration\"] = stream_df_numeric[\"Duration\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df_numeric.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim(stream_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary(stream_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_report = sv.analyze(stream_df_numeric)\n",
    "my_report.show_html()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering: categorical\n",
    "- one hot encoding for ports\n",
    "- word2vec encoding for payload (add payload to `stream_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add back payload\n",
    "stream_df_engineered = stream_df_numeric.join(mirai_df[\"Payload\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec for payload\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [simple_preprocess(payload) for payload in mirai_df[\"Payload\"]]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=sentences, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df_engineered[\"Payload_vectors\"] = stream_df_engineered[\"Payload\"].apply(\n",
    "    lambda payload: model.wv[simple_preprocess(payload)]\n",
    "    if simple_preprocess(payload)\n",
    "    else None\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "- models\n",
    "  - xgboost\n",
    "  - NN\n",
    "- k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are we training for? benign vs malicious"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
