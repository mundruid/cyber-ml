{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sweetviz as sv\n",
    "import ipaddress\n",
    "\n",
    "from scapy.all import PcapReader, IP, TCP, UDP, ICMP\n",
    "from scipy.stats import ttest_ind, kstest, norm, skew, kurtosis, zscore\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from skimpy import skim\n",
    "from summarytools import dfSummary\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcap_reader_mirai = PcapReader(\"../data/blog_eda/mirai.pcap\")\n",
    "pcap_reader_benign = PcapReader(\"../data/blog_eda/benign.pcapng\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "- convert data to streams\n",
    "- collect some numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcap_to_dataframe(pcap_reader: PcapReader) -> pd.DataFrame:\n",
    "    \"\"\"Converts raw packet capture to a Pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "        pcap_reader (PcapReader): packet capture read using scapy\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with pcap data\n",
    "    \"\"\"\n",
    "    # Create an empty list to store the data\n",
    "    data = []\n",
    "\n",
    "    # Iterate through the packets in the pcap file\n",
    "    for packet in pcap_reader:\n",
    "        # Get the source and destination IP addresses\n",
    "        if packet.haslayer(IP):\n",
    "            src_ip = packet[IP].src\n",
    "            dst_ip = packet[IP].dst\n",
    "            protocol = packet[IP].proto\n",
    "        else:\n",
    "            src_ip = None\n",
    "            dst_ip = None\n",
    "            protocol = None\n",
    "\n",
    "        # Get the source and destination ports and payload\n",
    "        if packet.haslayer(TCP):\n",
    "            src_port = packet[TCP].sport\n",
    "            dst_port = packet[TCP].dport\n",
    "            payload = str(packet[TCP].payload)\n",
    "            packet_len = len(packet[TCP])\n",
    "        elif packet.haslayer(UDP):\n",
    "            src_port = packet[UDP].sport\n",
    "            dst_port = packet[UDP].dport\n",
    "            payload = str(packet[UDP].payload)\n",
    "            packet_len = len(packet[UDP])\n",
    "        elif packet.haslayer(ICMP):\n",
    "            payload = str(packet[ICMP].payload)\n",
    "            packet_len = len(packet[ICMP])\n",
    "            src_port = None\n",
    "            dst_port = None\n",
    "        else:\n",
    "            src_port = None\n",
    "            dst_port = None\n",
    "            payload = str(packet.payload)\n",
    "            packet_len = len(packet)\n",
    "\n",
    "        # Append the data to the list\n",
    "        data.append(\n",
    "            [\n",
    "                packet.time,\n",
    "                src_ip,\n",
    "                dst_ip,\n",
    "                src_port,\n",
    "                dst_port,\n",
    "                payload,\n",
    "                packet_len,\n",
    "                protocol,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Convert the list to a pandas dataframe\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\n",
    "            \"Timestamp\",\n",
    "            \"Source IP\",\n",
    "            \"Destination IP\",\n",
    "            \"Source Port\",\n",
    "            \"Destination Port\",\n",
    "            \"Payload\",\n",
    "            \"Packet Length\",\n",
    "            \"Protocol\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment this out if this is the first run\n",
    "# because it takes too much time to convert to dataframe, use pkl on consequent runs\n",
    "# mirai_df = pcap_to_dataframe(pcap_reader_mirai)\n",
    "# benign_df = pcap_to_dataframe(pcap_reader_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pkl since dataframe conversion takes a long time\n",
    "# mirai_df.to_pickle(\"../data/blog_eda/mirai.pkl\")\n",
    "# benign_df.to_pickle(\"../data/blog_eda/benign.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_df = pd.read_pickle(\"../data/blog_eda/mirai.pkl\")\n",
    "benign_df = pd.read_pickle(\"../data/blog_eda/benign.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flows(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create an empty list to store stream data as separate dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Group packets by src/dst IP and src/dst port\n",
    "    grouped = df.groupby(\n",
    "        [\"Source IP\", \"Destination IP\", \"Source Port\", \"Destination Port\", \"Protocol\"]\n",
    "    )\n",
    "\n",
    "    # Iterate through each group to extract stream data\n",
    "    for name, group in grouped:\n",
    "        # Get source/destination IP, port, and protocol\n",
    "        src_ip, dst_ip, src_port, dst_port, proto = name\n",
    "\n",
    "        # Get number of packets, total length, and duration of the stream\n",
    "        num_packets = len(group)\n",
    "        total_length = group[\"Packet Length\"].sum()\n",
    "        start_time = group[\"Timestamp\"].min()\n",
    "        end_time = group[\"Timestamp\"].max()\n",
    "        duration = float(end_time - start_time)\n",
    "\n",
    "        # Create a new dataframe with the stream data\n",
    "        flow_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Source IP\": [src_ip],\n",
    "                \"Destination IP\": [dst_ip],\n",
    "                \"Source Port\": [src_port],\n",
    "                \"Destination Port\": [dst_port],\n",
    "                \"Protocol\": [proto],\n",
    "                \"Number of Packets\": [num_packets],\n",
    "                \"Total Length\": [total_length],\n",
    "                \"Duration\": [duration],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Add the new dataframe to the list\n",
    "        dfs.append(flow_df)\n",
    "\n",
    "    # Concatenate all the dataframes in the list into one dataframe\n",
    "    flow_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Return the new dataframe with stream data\n",
    "    return flow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_flow_df = extract_flows(mirai_df)\n",
    "benign_flow_df = extract_flows(benign_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "Exploratory Data Analysis approaches the dataset as a black box that we need to visualize and analyze statistically with the following goals:\n",
    "- get insights about our data\n",
    "- test hypotheses\n",
    "- decide on models and further processing, such as feature engineering.\n",
    "\n",
    "EDA can be performed for benign and malicious data. Here we are looking at EDA only for malicious data, however the same functions can be applied to benign."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics & data\n",
    "\n",
    "- Describe columns and data types\n",
    "- Descriptive statistics\n",
    "  -  count, \n",
    "  -  mean, \n",
    "  -  standard deviation, \n",
    "  -  minimum, \n",
    "  -  25th percentile, \n",
    "  -  median (50th percentile), \n",
    "  -  75th percentile, and \n",
    "  -  maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe, summarize etc.\n",
    "mirai_flow_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirai_flow_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics\n",
    "mirai_flow_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix for numerical values in dataframe\n",
    "mirai_flow_df.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "- Is the difference between two groups or variables statistically significant?\n",
    "- Use t-test to compare means of two groups\n",
    "  - assumes that data follows normal distribution\n",
    "- Types of variables\n",
    "  - dependent: the effect of a phenomenon. For example, how does number of HTTP requests mean that a network is compromised?\n",
    "  - independent: the cause. The number of HTTP requests affects whether a network is compromised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_testing(df1, df2, col):\n",
    "    group1 = df1[col]\n",
    "    group2 = df2[col]\n",
    "    pvalue = ttest_ind(group1, group2)[1]\n",
    "    if pvalue < 0.05:\n",
    "        return \"The difference between benign and mirai traffic {} is statistically significant (p < 0.05)\".format(\n",
    "            col\n",
    "        )\n",
    "    else:\n",
    "        return \"The difference between benign and mirai traffic {} is not statistically significant (p >= 0.05)\".format(\n",
    "            col\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_testing(mirai_flow_df, benign_flow_df, \"Number of Packets\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "- observation that significantly differs from others in a dataset\n",
    "- Causes\n",
    "  - measurement errors\n",
    "  - extreme rare values\n",
    "- significant impact in statistical analysis\n",
    "- measurements\n",
    "  - z-score: `(x - mean) / std_dev`\n",
    "  - IQR method: this method identifies outliers as observations that are below `Q1 - 1.5IQR` or above `Q3 + 1.5IQR`, where Q1 and Q3 are the first and third quartiles, and IQR is the interquartile range (the difference between Q3 and Q1).\n",
    "  - visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_zscore(df, column, threshold=3):\n",
    "    zscores = np.abs(zscore(df[column]))\n",
    "    return df[zscores > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = detect_outliers_zscore(mirai_flow_df, \"Total Length\", threshold=3)\n",
    "print(outliers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ip address to numeric values\n",
    "def ip_to_numeric(ip):\n",
    "    ip_obj = ipaddress.ip_interface(ip)\n",
    "    return int(ip_obj.network.network_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert IPs to numeric mirai data\n",
    "mirai_flow_df[\"Source IP Numeric\"] = mirai_flow_df[\"Source IP\"].apply(ip_to_numeric)\n",
    "mirai_flow_df[\"Destination IP Numeric\"] = mirai_flow_df[\"Destination IP\"].apply(\n",
    "    ip_to_numeric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert IPs to numeric benign data\n",
    "benign_flow_df[\"Source IP Numeric\"] = benign_flow_df[\"Source IP\"].apply(ip_to_numeric)\n",
    "benign_flow_df[\"Destination IP Numeric\"] = benign_flow_df[\"Destination IP\"].apply(\n",
    "    ip_to_numeric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of non numeric columns for IPs\n",
    "mirai_flow_df_numeric = mirai_flow_df.drop(columns=[\"Source IP\", \"Destination IP\"])\n",
    "benign_flow_df_numeric = benign_flow_df.drop(columns=[\"Source IP\", \"Destination IP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert duration from object to float\n",
    "mirai_flow_df[\"Duration\"] = mirai_flow_df_numeric[\"Duration\"].astype(float)\n",
    "benign_flow_df[\"Duration\"] = benign_flow_df_numeric[\"Duration\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all data types are numeric now\n",
    "mirai_flow_df_numeric.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframes to pickles, can be used in the next blog\n",
    "mirai_flow_df_numeric.to_pickle(\"../data/blog_eda/mirai_flow_numeric.pkl\")\n",
    "benign_flow_df_numeric.to_pickle(\"../data/blog_eda/benign_flow_numeric.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More EDA\n",
    "After converting all columns to numerical, we can do more exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = mirai_flow_df_numeric.corr()\n",
    "\n",
    "# Print the correlation matrix and autocorrelation\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the autocorrelation for a specific column (e.g., 'Number of Packets')\n",
    "autocorrelation = mirai_flow_df_numeric[\"Number of Packets\"].autocorr()\n",
    "\n",
    "print(\"\\nAutocorrelation for 'Number of Packets':\")\n",
    "print(autocorrelation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summaries & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim(mirai_flow_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim(benign_flow_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary(mirai_flow_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary(benign_flow_df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_report = sv.analyze(mirai_flow_df_numeric)\n",
    "my_report.show_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_report = sv.analyze(benign_flow_df_numeric)\n",
    "my_report.show_html()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
