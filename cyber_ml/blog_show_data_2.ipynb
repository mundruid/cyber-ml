{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syslogmp import parse\n",
    "\n",
    "\n",
    "def load_syslog(log_message: str) -> dict:\n",
    "    message = parse(log_message)\n",
    "\n",
    "    return {\n",
    "        \"timestamp\": message.timestamp,\n",
    "        \"hostname\": message.hostname,\n",
    "        \"message\": message.message,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "log_message = bytes(\"<133>Feb 25 14:09:07 webserver syslogd: restart\", \"utf-8\")\n",
    "log_data = load_syslog(log_message)\n",
    "print(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def process_syslog(log_message):\n",
    "    log_regex = r\"^(\\w{3}\\s\\d{1,2}\\s\\d{2}:\\d{2}:\\d{2})\\s(\\S+)\\s(\\S+):\\s\\[(\\d+)\\]\\s(.*)$\"\n",
    "    # The above regex pattern captures the following groups:\n",
    "    # 1. Timestamp\n",
    "    # 2. Hostname\n",
    "    # 3. Application\n",
    "    # 4. PID\n",
    "    # 5. Message\n",
    "\n",
    "    match = re.match(log_regex, log_message)\n",
    "    if not match:\n",
    "        return None\n",
    "\n",
    "    timestamp = match.group(1)\n",
    "    hostname = match.group(2)\n",
    "    application = match.group(3)\n",
    "    pid = int(match.group(4))\n",
    "    message = match.group(5)\n",
    "\n",
    "    return {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"hostname\": hostname,\n",
    "        \"application\": application,\n",
    "        \"pid\": pid,\n",
    "        \"message\": message,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "log_message = \"Feb 28 14:21:30 example-hostname kernel: [12345] This is a log message\"\n",
    "log_data = process_syslog(log_message)\n",
    "print(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "import pandas as pd\n",
    "\n",
    "legit_domains = pd.read_csv(\"../data/blog_show_data/top-1m.csv\", names=[\"domain\"])\n",
    "legit_domains[\"tld\"] = [tldextract.extract(d).domain for d in legit_domains[\"domain\"]]\n",
    "legit_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urlextract\n",
    "\n",
    "# Create an instance of URLExtract class\n",
    "url_extractor = urlextract.URLExtract()\n",
    "\n",
    "# Sample text containing URLs to be extracted\n",
    "text_with_urls = \"www.googleadservices.com: type A, class IN, addr 142.251.32.194\"\n",
    "\n",
    "# Extract URLs from the given text\n",
    "extracted_urls = url_extractor.find_urls(text_with_urls)\n",
    "\n",
    "print(\"Extracted URLs: \", extracted_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mirai_data = pd.read_csv(\"../data/blog_show_data/mirai.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import rdpcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcap = rdpcap(\"../data/blog_show_data/2023-01-23-Google-ad-to-possible-TA505-activity.pcap\")\n",
    "type(pcap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import *\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "def parse_http_payload(packet):\n",
    "    # check if there is payload in packet\n",
    "    if packet.haslayer(TCP) and packet.haslayer(Raw):\n",
    "        try:\n",
    "            payload = str(packet[Raw].load, \"utf-8\")\n",
    "            \n",
    "            # is it http?\n",
    "            if \"HTTP/\" in payload:\n",
    "                print(payload)\n",
    "                body = None\n",
    "                if \"\\r\\n\\r\\n\" in payload:\n",
    "                    body = payload.split(\"\\r\\n\\r\\n\")[1]\n",
    "                else:\n",
    "                    body = payload.split(\"<!DOCTYPE html>\")[1]\n",
    "                http_request = payload.split(\"\\r\\n\")\n",
    "                try:\n",
    "                    # this generates a ValueError if the http request does not have the proper structure \n",
    "                    method, path, protocol = http_request[0].split(\" \")\n",
    "                    print(method, path, protocol)\n",
    "                    headers = {}\n",
    "                    for header in http_request[1:]:\n",
    "                        if header:\n",
    "                            header_name, header_value = header.split(\":\", maxsplit=1)\n",
    "                            headers[header_name] = header_value.strip()\n",
    "                    parsed_path = urllib.parse.urlparse(path)\n",
    "                    return {\n",
    "                        \"timestamp\": str(packet.time),\n",
    "                        \"source_ip\": packet[IP].src,\n",
    "                        \"dest_ip\": packet[IP].dst,\n",
    "                        \"source_port\": packet[TCP].sport,\n",
    "                        \"dest_port\": packet[TCP].dport,\n",
    "                        \"method\": method,\n",
    "                        \"path\": parsed_path.path,\n",
    "                        \"query_string\": parsed_path.query,\n",
    "                        \"protocol\": protocol,\n",
    "                        \"headers\": headers,\n",
    "                        \"body\": body,\n",
    "                    }\n",
    "                # else:\n",
    "                except:\n",
    "                    # http header may be non-standard, may have no method or may be  error code like 302\n",
    "                    return {\n",
    "                        \"timestamp\": str(packet.time),\n",
    "                        \"source_ip\": packet[IP].src,\n",
    "                        \"dest_ip\": packet[IP].dst,\n",
    "                        \"source_port\": packet[TCP].sport,\n",
    "                        \"dest_port\": packet[TCP].dport,\n",
    "                        \"body\": body,\n",
    "                    }\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "# read a malicious packet capture downloaded from https://malware-traffic-analysis.net/\n",
    "pcap = rdpcap(\"../data/blog_show_data/2023-01-23-Google-ad-to-possible-TA505-activity.pcap\")\n",
    "\n",
    "for packet in pcap:\n",
    "    parsed_payload = parse_http_payload(packet)\n",
    "    if parsed_payload != None:\n",
    "        print(parsed_payload)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipyflow)",
   "language": "python",
   "name": "ipyflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "bcb17974934df3f13e9a43dbe9161769086c0c22330c6ed418c43eb90898dbd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
